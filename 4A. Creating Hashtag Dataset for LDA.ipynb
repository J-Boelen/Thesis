{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the .db files and combining them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hashtags dataframe\n",
    "Hashtags = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all monthly files containing the information about hashtags\n",
    "# Connect with the db file and create cursor object to be able to execute queries\n",
    "year = 2012\n",
    "month = 1\n",
    "\n",
    "yearStr = ''\n",
    "monthStr = ''\n",
    "\n",
    "while year < 2019:\n",
    "    \n",
    "    while month < 13:\n",
    "        \n",
    "        # Change the month to corresponding string.\n",
    "        if month == 1:\n",
    "            monthStr = '01'\n",
    "        if month == 2:\n",
    "            monthStr = '02'    \n",
    "        if month == 3:\n",
    "            monthStr = '03'\n",
    "        if month == 4:\n",
    "            monthStr = '04'\n",
    "        if month == 5:\n",
    "            monthStr = '05'\n",
    "        if month == 6:\n",
    "            monthStr = '06'\n",
    "        if month == 7:\n",
    "            monthStr = '07'    \n",
    "        if month == 8:\n",
    "            monthStr = '08'\n",
    "        if month == 9:\n",
    "            monthStr = '09'\n",
    "        if month == 10:\n",
    "            monthStr = '10'\n",
    "        if month == 11:\n",
    "            monthStr = '11'\n",
    "        if month == 12:\n",
    "            monthStr = '12'\n",
    "        \n",
    "        yearStr = str(year)\n",
    "        # Create connection\n",
    "        connection = sqlite3.connect('/Volumes/Hard drive/Thesis/Data/' + yearStr + '/month_' + yearStr + '_' + monthStr +'.db')\n",
    "        cursor = connection.cursor()\n",
    "        try:\n",
    "            # Read media nl file and store it in the final dataframe.\n",
    "            media = pd.read_sql_query(\"SELECT * FROM hashtags_NL\", connection)\n",
    "            Hashtags = Hashtags.append(media)\n",
    "        except:\n",
    "            print('skipped')\n",
    "        # Add one month\n",
    "        month += 1\n",
    "        \n",
    "    # Reset month\n",
    "    month = 1\n",
    "    \n",
    "    # Add one year\n",
    "    year += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write to csv file.\n",
    "Hashtags.to_csv('CSV/TwitterHashtags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a hashtag dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hashtags=Hashtags.rename(columns={'text':'hashtags'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HashtagDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueItems = list(Hashtags['item_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of hashtags per item (per tweet)\n",
    "for i in uniqueItems:\n",
    "    \n",
    "    # Create a dataframe with only hashtags for this item.\n",
    "    hashtagsForThisItem = Hashtags[Hashtags['item_number'] == i]\n",
    "    \n",
    "    # Creat an empty list to fill with the hashtags.\n",
    "    hashtagList = []\n",
    "    \n",
    "    # Iterate over the created dataframe to fill in the hashtagList.\n",
    "    for index, row in hashtagsForThisItem.iterrows():\n",
    "        hashtagList.append(row['hashtags'])\n",
    "    \n",
    "    # Update the dictionary with a key value pair.\n",
    "    HashtagDict[i] = hashtagList\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame.from_dict(HashtagDict, orient='index')\n",
    "\n",
    "# Save it to a .csv\n",
    "df.to_csv('TwitterHashtags_Processed.csv')\n",
    "\n",
    "# Import the .csv to change the column name of 'unnamed: 0' to 'item_number'.\n",
    "df_temp = pd.read_csv('TwitterHashtags_Processed.csv', sep= ',', low_memory = False, lineterminator='\\n')\n",
    "\n",
    "# Rename the column.\n",
    "df_temp = df_temp.rename(columns={'Unnamed: 0':'item_number'})\n",
    "\n",
    "# Export the final dataframe to .csv\n",
    "df_temp.to_csv('TwitterHashtags_Processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping tweets based on hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tourist dataset\n",
    "Tourists = pd.read_csv('tourists_total.csv', sep= ',', low_memory = False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter on language, starting with english, netherlands, spanish, french, german\n",
    "Tourists = Tourists[Tourists['lang'] == 'de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tourists['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hashtag dataset\n",
    "Hashtags = pd.read_csv('TwitterHashtags_Processed.csv', sep= ',', low_memory = False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LDA dataset with only the necessary information.\n",
    "LDA_Total = Tourists[['item_number','text','lang']]\n",
    "\n",
    "# Merge the dataset so that it contains the hashtags per tweet.\n",
    "LDA_Total = pd.merge(LDA_Total, Hashtags, on='item_number', how='left')\n",
    "\n",
    "# Store all the hashtags in one string per tweet.\n",
    "hashtagStringDict = {}\n",
    "\n",
    "# Iterate over the entire dataframe to fill the dictionary.\n",
    "for index, row in LDA_Total.iterrows():\n",
    "    \n",
    "    # Create a hashtag list.\n",
    "    hashtagList = []\n",
    "        \n",
    "    # Create missing value list.\n",
    "    missingValueList = list(row.isnull())[3:]\n",
    "        \n",
    "    # Iterate over all the hashtag columns and check if it is a missing value.\n",
    "    for i in range(41):\n",
    "        if missingValueList[i] == False:\n",
    "            hashtagList.append(row[str(i)])\n",
    "        \n",
    "    # Store all the hashtags in one string\n",
    "    hashtagString = ', '.join(hashtagList)\n",
    "    hashtagStringDict[row['item_number']] = hashtagString\n",
    "    \n",
    "# Change the dictionary to a dataframe.\n",
    "HashtagInfo_LDA = pd.DataFrame(hashtagStringDict, index=['hashtags']).T\n",
    "HashtagInfo_LDA['item_number'] = HashtagInfo_LDA.index   \n",
    "\n",
    "# Merge the newly created dataframe and drop all unneccessary columns.\n",
    "LDA_Total = pd.merge(LDA_Total, HashtagInfo_LDA, on='item_number', how='inner')\n",
    "LDA_Total = LDA_Total[['item_number','text','lang','hashtags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_Total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the newly created dataframe to create a set of hashtags.\n",
    "\n",
    "# Empty list of hashtags\n",
    "hashtagList_Total = []\n",
    "\n",
    "for index, row in LDA_Total.iterrows():\n",
    "    \n",
    "    # Create individual list\n",
    "    individualList = row['hashtags'].split(',')\n",
    "    \n",
    "    # Iterate over the individual list\n",
    "    for i in individualList:\n",
    "        \n",
    "        # Append to the total list\n",
    "        hashtagList_Total.append(i)\n",
    "\n",
    "# Transform into a set to retain only unique hashtags, then transform it back to a list to make it iterable.\n",
    "hashtagList_Total = set(hashtagList_Total)\n",
    "hashtagList_Total = list(hashtagList_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, all tweets that contain a certain hashtag need to be aggregated based on that hashtag.\n",
    "\n",
    "# Empty list, will contain [Hashtag, comma separated item_number, total text]\n",
    "Hashtags_Aggregated = []\n",
    "\n",
    "# Iterate over the newly created dataframe.\n",
    "for index, row in LDA_Total.iterrows():\n",
    "    \n",
    "    # For each row, get the hashtags and put them in a list.\n",
    "    indiv_Tweet_HashtagList = row['hashtags'].split(',')\n",
    "    \n",
    "    \n",
    "    # Create index list to use in the dictionary update after the loop\n",
    "    indexes = []\n",
    "    \n",
    "    # Iterate over that list and see if it is in the total hashtag list (should always be the case)\n",
    "    for i in indiv_Tweet_HashtagList:\n",
    "        \n",
    "        # If the hashtag is in the list, find the index of that hashtag.\n",
    "        if i in hashtagList_Total:\n",
    "            \n",
    "            # Get the index.\n",
    "            indexes.append(hashtagList_Total.index(i))\n",
    "    \n",
    "    # For each index, create new entry in the 2d list.\n",
    "    for i in indexes:\n",
    "        \n",
    "        # Get the value.\n",
    "        value = hashtagList_Total[i]\n",
    "        \n",
    "        # List comprehesion to get the first item of each item.\n",
    "        hashtagListTemp = [x[0] for x in Hashtags_Aggregated]\n",
    "        \n",
    "        # If the value is already in the 2d list.\n",
    "        if value in hashtagListTemp:\n",
    "            \n",
    "            # Get the index.\n",
    "            indexOfValue = hashtagListTemp.index(value)\n",
    "            \n",
    "            # Update the values that belong to this index/hashtag\n",
    "            Hashtags_Aggregated[indexOfValue][1] += (', ' + str(row['item_number'])) # Add item number.\n",
    "            Hashtags_Aggregated[indexOfValue][2] += (' ' + row['text']) # Add text.\n",
    "        \n",
    "        # Else just add it to the list.\n",
    "        else:\n",
    "            Hashtags_Aggregated.append([value, str(row['item_number']), row['text']])\n",
    "            \n",
    "    print((index/len(LDA_Total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all the information.\n",
    "LDA_Hashtag_Total = pd.DataFrame(Hashtags_Aggregated, columns = ['hashtag', 'matched_items', 'text'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LDA_Hashtag_Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv file.\n",
    "LDA_Hashtag_Total.to_csv('TwitterHashtags_LDA_DE.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
